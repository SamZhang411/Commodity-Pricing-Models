{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1080 candidates, totalling 5400 fits\n",
      "Best parameters found by GridSearchCV:\n",
      "{'regressor__bootstrap': False, 'regressor__max_depth': 10, 'regressor__max_features': 'sqrt', 'regressor__min_samples_leaf': 1, 'regressor__min_samples_split': 2, 'regressor__n_estimators': 200}\n",
      "Model saved to ./soybeans_model_v1.pkl\n",
      "Test MSE: 8521.6602\n",
      "Test R²: 0.9080\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/soybeans_model_input.csv'\n",
    "data_df = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "# Parameters and targets\n",
    "parameters = ['STU, US', 'STU, AR', 'STU, BR', 'STU, Corn', 'Gold', 'DX', 'Crude', 'GDP (Bn USD)']\n",
    "targets = ['Price_High', 'Price_Low', 'Price_Average']\n",
    "\n",
    "# Drop NaN values\n",
    "combined_data = data_df[parameters + targets].dropna()\n",
    "\n",
    "# Split the data into features (X) and targets (y)\n",
    "X = combined_data[parameters]\n",
    "y = combined_data[targets]\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline with StandardScaler and RandomForestRegressor\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200, 300, 500],\n",
    "    'regressor__max_depth': [None, 10, 20, 30, 40],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "    'regressor__max_features': [None, 'sqrt', 'log2'],\n",
    "    'regressor__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after tuning\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found by GridSearchCV:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "model_filename = './soybeans_model_v1.pkl'\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(f\"Test MSE: {mse_test:.4f}\")\n",
    "print(f\"Test R²: {r2_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'regressor__bootstrap': False,\n",
    "'regressor__max_depth': 10,\n",
    "'regressor__max_features': 'sqrt',\n",
    "'regressor__min_samples_leaf': 1,\n",
    "'regressor__min_samples_split': 2,\n",
    "'regressor__n_estimators': 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def predict_prices(input, model):\n",
    "    # if isinstance(input, pd.DataFrame):\n",
    "    #     input = input.values\n",
    "    input = np.array(input).reshape(1, -1)\n",
    "    prediction = model.predict(input)\n",
    "    high_price, low_price, avg_price = prediction[0]\n",
    "    \n",
    "    return high_price, low_price, avg_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted High Price: 1163.7844791958448\n",
      "Predicted Low Price: 1093.4929920634922\n",
      "Predicted Average Price: 1128.3738035913673\n",
      "Predicted High Price w/ Today's Open: 1152.7626979166664\n",
      "Predicted Low Price w/ Today's Open: 1087.40375\n",
      "Predicted Average Price w/ Today's Open: 1118.1024522569448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhang/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/zhang/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "wasde_path = '../data/input_data/wasde0824.csv'\n",
    "gold_path = '../data/input_data/gcy.csv'\n",
    "dx_path = '../data/input_data/dxy.csv'\n",
    "crude_path = '../data/input_data/qay.csv'\n",
    "\n",
    "wasde_data = pd.read_csv(wasde_path)\n",
    "gold_data = pd.read_csv(gold_path)\n",
    "dx_data = pd.read_csv(dx_path)\n",
    "crude_data = pd.read_csv(crude_path)\n",
    "\n",
    "corn_data = wasde_data[\n",
    "    (wasde_data['ReportTitle'] == 'World Corn Supply and Use') &\n",
    "    (wasde_data['Region'] == 'United States') &\n",
    "    (wasde_data['ProjEstFlag'] == 'Proj.')\n",
    "]\n",
    "\n",
    "corn_stock = corn_data[corn_data['Attribute'] == 'Ending Stocks']['Value'].values[0]\n",
    "corn_use = corn_data[corn_data['Attribute'] == 'Domestic Total']['Value'].values[0]\n",
    "stu_corn = corn_stock / corn_use if corn_use != 0 else None\n",
    "\n",
    "soybean_data = wasde_data[\n",
    "    (wasde_data['ReportTitle'] == 'World Soybean Supply and Use') &\n",
    "    (wasde_data['ProjEstFlag'] == 'Proj.')\n",
    "]\n",
    "\n",
    "stu_us, stu_ar, stu_br = None, None, None\n",
    "\n",
    "for region in ['United States', 'Argentina', 'Brazil']:\n",
    "    region_data = soybean_data[soybean_data['Region'] == region]\n",
    "    stock = region_data[region_data['Attribute'] == 'Ending Stocks']['Value'].values[0]\n",
    "    use = region_data[region_data['Attribute'] == 'Domestic Total']['Value'].values[0]\n",
    "    \n",
    "    if use != 0:\n",
    "        if region == 'United States':\n",
    "            stu_us = stock / use\n",
    "        elif region == 'Argentina':\n",
    "            stu_ar = stock / use\n",
    "        elif region == 'Brazil':\n",
    "            stu_br = stock / use\n",
    "\n",
    "\n",
    "gold_curr, dx_curr, crude_curr = None, None, None\n",
    "gold_curr = gold_data['Open'][0]\n",
    "dx_curr = dx_data['Open'][0]\n",
    "crude_curr = crude_data['Open'][0]\n",
    "\n",
    "gold_avg = gold_data['Open'].head(15).mean()\n",
    "dx_avg = dx_data['Open'].head(15).mean()\n",
    "crude_avg = crude_data['Open'].head(15).mean()\n",
    "\n",
    "gdp = 28630.0\n",
    "\n",
    "model = joblib.load('./soybeans_model_v1.pkl')\n",
    "parameters = ['STU, US', 'STU, AR', 'STU, BR', 'STU, Corn', 'Gold', 'DX', 'Crude', 'GDP (Bn USD)']\n",
    "\n",
    "input_avg = [stu_us, stu_ar, stu_br, stu_corn, gold_avg, dx_avg, crude_avg, gdp]\n",
    "input_curr = [stu_us, stu_ar, stu_br, stu_corn, gold_curr, dx_curr, crude_curr, gdp]\n",
    "input_avg = pd.DataFrame([input_avg], columns=parameters)\n",
    "input_curr = pd.DataFrame([input_curr], columns=parameters)\n",
    "\n",
    "# Scale the input data\n",
    "# input_avg_scaled = scaler.transform(input_avg)\n",
    "# input_curr_scaled = scaler.transform(input_curr)\n",
    "\n",
    "input_avg = [stu_us, stu_ar, stu_br, stu_corn, gold_avg, dx_avg, crude_avg, gdp]\n",
    "input_curr = [stu_us, stu_ar, stu_br, stu_corn, gold_curr, dx_curr, crude_curr, gdp]\n",
    "high_curr, low_curr, avg_curr = predict_prices(input_curr, model)\n",
    "high, low, avg = predict_prices(input_avg, model)\n",
    "\n",
    "print(f\"Predicted High Price: {high}\")\n",
    "print(f\"Predicted Low Price: {low}\")\n",
    "print(f\"Predicted Average Price: {avg}\")\n",
    "\n",
    "print(f\"Predicted High Price w/ Today's Open: {high_curr}\")\n",
    "print(f\"Predicted Low Price w/ Today's Open: {low_curr}\")\n",
    "print(f\"Predicted Average Price w/ Today's Open: {avg_curr}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
